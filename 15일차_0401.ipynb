{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkGiNc3qawjwZ9SqznHgUp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyyy11/colab0000/blob/main/15%EC%9D%BC%EC%B0%A8_0401.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtuCp5HivRGi",
        "outputId": "477cce7b-0fcc-4a1e-df23-35dec3345ce0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "\"그럼, 여러분은 이렇게 강이라고 하거나 우유가 흐른 흔적이라고 말하고 있는 이 희미하고 하얀 것이 실제로는 무엇인지 알고 있습니까?\" 선생님은 칠판에 걸어 놓은 커다란 검은 별자리 지도의 위에서 아래쪽으로 희뿌연 띠 모양을 한 은하를 가리키며 모두에게 질문을 던졌습니다.\n",
            "캄파넬라가 손을 들었습니다. 그리고 나서 네다섯 명이 손을 더 들었습니다. 조바니도 손을 들려고 하다가 황급히 그대로 멈추었습니다. 분명 그것이 모두 별이라고 언젠가 잡지에서 읽었지만, 요즘은 조바니는 교실에서도 졸고, 책을 읽을 틈도 읽을 책도 없기 때문에 왠지 아는 게 아무것도 없는 듯한 기분이 들었습니다.\n",
            "그런데 선생님은 벌써 그것을 눈치챘습니다.\n",
            "\"조바니, 너는 알고 있겠지?\"\n",
            "조바니는 기세 좋게 일어났지만 막상 일어나보니 분명하게 대답할 수가 없었습니다. 자네리가 앞자리에서 뒤돌아보고 조바니를 보고 키득키득 웃었습니다. 조바니는 더 당황해서 얼굴이 새빨개졌습니다. 선생님이 또 말했습니다.\n",
            "\"큰 망원경으로 \n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#Google 드라이브상의 텍스트 데이터로의 경로를 지정하세요\n",
        "nov_path = '/content/drive/MyDrive/' + 'Colab Notebooks Source Code_샘플데이터/Chapter8/novels/은하철도의 밤.txt'\n",
        "\n",
        "#파일을 읽어 들인다\n",
        "with open(nov_path, 'r') as f:\n",
        "    nov_text = f.read()\n",
        "    print(nov_text[:500])    #첫 500문자만 표시시"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re #정규표현에 필요한 라이브러리\n",
        "\n",
        "text = re.sub(\"[|  ]\", \"\", nov_text)      #|과 공백의 삭제\n",
        "print(\"문자 수\", len(text))     #len()으로 문자열의 문자 수도 취득 가능"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqy2TCEe4i6k",
        "outputId": "ecee3f3e-5305-4295-ed44-6120f8fadf70"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 수 1721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_rnn = 10     #시계열의 수\n",
        "batch_size = 128\n",
        "epochs = 60\n",
        "n_mid = 128   #중간층의 뉴런 수수"
      ],
      "metadata": {
        "id": "q715tDFO5eR0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# 인덱스와 문자로 사전을 작성\n",
        "chars = sorted(list(set(text)))  # set으로 문자의 중복을 없애고, 각 문자를 리스트에 저장한다\n",
        "print(\"문자 수(중복 없음)\", len(chars))\n",
        "char_indices = {}  # 문자가 키로 인덱스가 값\n",
        "for i, char in enumerate(chars):\n",
        "    char_indices[char] = i\n",
        "indices_char = {}  # 인덱스가 키로 문자가 값\n",
        "for i, char in enumerate(chars):\n",
        "    indices_char[i] = char\n",
        "\n",
        "# 시계열로 늘어선 문자와 그 다음에 예측해야 할 문자를 꺼낸다\n",
        "time_chars = []  # 시계열에 늘어선 문자\n",
        "next_chars = []  # 예측해야 할 문자\n",
        "for i in range(0, len(text) - n_rnn):\n",
        "    time_chars.append(text[i: i + n_rnn])\n",
        "    next_chars.append(text[i + n_rnn])\n",
        "\n",
        "# 입력과 정답을 one-hot 표현으로 나타냅니다\n",
        "x = np.zeros((len(time_chars), n_rnn, len(chars)), dtype=np.bool_)  # 입력\n",
        "t = np.zeros((len(time_chars), len(chars)), dtype=np.bool_)  # 정답\n",
        "for i, t_cs in enumerate(time_chars):\n",
        "    t[i, char_indices[next_chars[i]]] = 1  # 정답을 one-hot 표현으로 나타낸다\n",
        "    for j, char in enumerate(t_cs):\n",
        "        x[i, j, char_indices[char]] = 1  # 입력을 one-hot 표현으로 나타낸다\n",
        "        \n",
        "print(\"x의 형태\", x.shape)\n",
        "print(\"t의 형태\", t.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtHTEoaZ6J2Q",
        "outputId": "968f3d29-b609-445d-c8f0-545094901a24"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "문자 수(중복 없음) 301\n",
            "x의 형태 (1711, 10, 301)\n",
            "t의 형태 (1711, 301)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, SimpleRNN, LSTM, GRU\n",
        "\n",
        "#일반적인 RNN\n",
        "model_rnn = Sequential()\n",
        "model_rnn.add(SimpleRNN(n_mid, input_shape=(n_rnn, len(chars))))\n",
        "model_rnn.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "print(model_rnn.summary())\n",
        "\n",
        "print()\n",
        "\n",
        "#LSTM\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(n_mid, input_shape=(n_rnn, len(chars))))\n",
        "model_lstm.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "print(model_lstm.summary())\n",
        "\n",
        "print()\n",
        "\n",
        "#GRU\n",
        "model_gru = Sequential()\n",
        "model_gru.add(GRU(n_mid, input_shape=(n_rnn, len(chars))))\n",
        "model_gru.add(Dense(len(chars), activation=\"softmax\"))\n",
        "model_gru.compile(loss='categorical_crossentropy', optimizer=\"adam\")\n",
        "print(model_gru.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GPcxSseHLO-",
        "outputId": "b1fd908e-c0dd-44f6-8248-12c4751da584"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "simple_rnn (SimpleRNN)       (None, 128)               55040     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 301)               38829     \n",
            "=================================================================\n",
            "Total params: 93,869\n",
            "Trainable params: 93,869\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               220160    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 301)               38829     \n",
            "=================================================================\n",
            "Total params: 258,989\n",
            "Trainable params: 258,989\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru (GRU)                    (None, 128)               165120    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 301)               38829     \n",
            "=================================================================\n",
            "Total params: 203,949\n",
            "Trainable params: 203,949\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.callbacks import LambdaCallback\n",
        " \n",
        "def on_epoch_end(epoch, logs):\n",
        "    print(\"에포크: \", epoch)\n",
        "\n",
        "    beta = 5  # 확률 분포를 조정하는 상수\n",
        "    prev_text = text[0:n_rnn]  # 입력에 사용하는 문자\n",
        "    created_text = prev_text  # 생성되는 텍스트\n",
        "    \n",
        "    print(\"시드: \", created_text)\n",
        "\n",
        "    for i in range(400):  # 400 문자를 생성한다\n",
        "        # 입력을 one-hot 표현으로\n",
        "        x_pred = np.zeros((1, n_rnn, len(chars)))\n",
        "        for j, char in enumerate(prev_text):\n",
        "            x_pred[0, j, char_indices[char]] = 1\n",
        "        \n",
        "        # 예측을 실시, 다음 문자를 얻는다\n",
        "        y = model.predict(x_pred)\n",
        "        p_power = y[0] ** beta  # 확률 분포의 조정\n",
        "        next_index = np.random.choice(len(p_power), p=p_power/np.sum(p_power))        \n",
        "        next_char = indices_char[next_index]\n",
        "\n",
        "        created_text += next_char\n",
        "        prev_text = prev_text[1:] + next_char\n",
        "\n",
        "    print(created_text)\n",
        "    print()\n",
        "\n",
        "# 에포크 종료 후에 실행할 함수를 설정\n",
        "epock_end_callback= LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "metadata": {
        "id": "uUNjjbuMISmA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 일반적인 RNN\n",
        "model = model_rnn\n",
        "history_rnn = model_rnn.fit(x, t,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    callbacks=[epock_end_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZ7kv6LrNkWq",
        "outputId": "4d1357c0-bc72-46cf-c439-e0470a52c6db"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4.6516\n",
            "에포크:  0\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게하이이이이다.는니다이이이는다하이은고이이다니다이이다니이하이은다이가다니다다는다니다.이.다이이다.다.다하다이이이이고하다.다.이니다다이다하다.가는하이이다이다다다이이이이다이다.다.이이이다이다.다.다이이다하다하다.다이이다하지이다이이다는다니다.이.니다하다은고이고이이지이이이이다다이이다이이은다다하다니다.이이니이하이하다이이다다다하다이이이이다이는가이.다이이다니다.다은이이이다.다하다하이이이고이다니다.이은고이이다.다이이이이이이다이다.이이.이이다이다이다니다.이다니다.다하다이이이하다라고하이이니다이이이이이이다이다이다가다이다다이이니다하다.다이이이는다하다.는이는다다이가고이이이다이고니다.이다다다이이은다하다다이이이이이다이다이가이다다하다하다이다이다이니이이이이다이다.다다이이는지이다하다고하이다이이을니다.다이고고하을하다.이.이이이은하다이다다이에는이\n",
            "\n",
            "Epoch 2/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 4.4984\n",
            "에포크:  1\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이하이이는이는이다.이이하파이다이다.이는이이라다.다이이이이는다이이이이이이는하다이는이가이이는하이이다.이이이다고가은다이니이는다다이이이이이고이이이이이이하이다이이이이이하다이다이이이이이이고는다이다.게이는이이다니다이이하고이이다하다이는이이이하고하다하다이이는에이하고이이이고이이는다이이는이이이는하이이이이이이이다하이는이이이이는다이이다이다이다이다이\n",
            "은하은하다이이이이이이이이고이다이다이이이는이이다하다이고이이이하이이이이이이는는이이는\n",
            "하이하는이이이고하이는라이이는는다이다.이이는이하고하다이이이이이이는이이이이이이이가다이는은는이다.그이다는이은이니이이는다다.이이이이이이다하이이고이는다이다이이이이이는고이는가이이고하다이이다이이하하이다이는가이는는이이다다.이이에이이이다이이고이이이에에다니다.이가이는하다.다이이이이이니다하다이는가이는하다이다는다이이이하이하고하하\n",
            "\n",
            "Epoch 3/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 4.3271\n",
            "에포크:  2\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는.이지하다이다다다이는이이이하는하고이은이다이이이하이이다는다이다는이이이다하다.다이이이이는하다.다하이이이는이이하고이이다는이다이라이이이다이이다하이하다이이이이이이이이이이다은은은이이이이이다다하다이이이이이다이하다이이이이이다이이이이이이하하다가이이이이수이는다이이이다이다고이고이이하다이다고이이이는이이이다이이다다이이다이이이다이니다하은이는이다이이지이이이다.다.나이이이이다하다하이이이이이다이은하이는가이는는이라이이다하이다고이이이하다이는다이이이은이이하하이이다하이니다이이이는다이이하고하다다다이이이지이이에다고이는.다이다이그이이다하은하에이이이하다이다이이그는이하다하다이\n",
            "이이이이이이이이이다이다이는이이는하다하고이이이이이이이이다이이은이다이다이다이하다하다하다이이이이이하다가이하하이이다라이이는이이이하다이이다이이는는이이이이다이이다고이하이하은이이다하이이이이\n",
            "\n",
            "Epoch 4/60\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 4.1563\n",
            "에포크:  3\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는이이는하다이다니이이이이이다하다하다는이이는는이다하이이이이이고이은이이이이는는다이다고이은하이니다.는이이이이이하다이고이에이이는이이하다이다이이이이는은이하다이이는는이다이이이이는이고는다이다이이은하은이다하이이는이이이이다이이하은이이는이이하는하이이는이다는다은이이이이는다이다이이이이는은고하다이이이이이다이이이이는이다하다이이는하이하다이이이이이이이이고이는이다.이는다이이이하은하는이다이는하하하이이이는이이는이이이는하다하하고이이은이이이이은이이는다이이이는이이이하고이다이이이이는이고이다이하는이이다다하다이것이이이다에이다하이하다하하이이는이이이고이이이하이이는다이이는는이이다이이이이이이이는다이이다이이이는이다이하은하이하다하다하하이이이는은하는하이이는이을이이이이이하다이다은는이하는이이하는것이다이이이는는하이하지이이이이이이이하이은이이하이는이는이다이는이이다하지이다\n",
            "\n",
            "Epoch 5/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 3.9546\n",
            "에포크:  4\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는이라고하고이다.것니다이이이니다.\n",
            "\n",
            "고이가는라다이이니다.가고다이하는하다.\n",
            "이고하는이이다이\n",
            "다.이이이하다가하다이이는는라다.이이이이이다.\n",
            "이는이이는하다이이다것이은고이이이는이이니다.이는는고이는하다.이것이이이다.지다하이이이하다이은은이이는는이다.다바이는것고니다.\n",
            "이고그다가이은이이는다이다하이이이는하다하다이이가는는니다.이하다.이다하고하이하이이이는이이이이이이는이다다다다가이이고하는이하고이이는라이고다는이이는이이이하고이이는것이는는는이이는하이가것니니니다을\n",
            "니다.이은에고니다.다.이이니다하다하고이이이하고이는니이이는는는이이이이고는다니다.\n",
            "이는이이고하다하는이이이는이이이하니다는다것이는이이라고니다.\n",
            "이고하이이이지이이는것이이다.\n",
            "은는을이가하은이하다고그은하이이이는습니다.\n",
            "이그이은고하은하바이이는것이이다.\n",
            "리는다이가하하이하다니다이을이이이이고하다\n",
            "\n",
            "Epoch 6/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 3.7670\n",
            "에포크:  5\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는이라는하바이는니다.다바이이보고이다하고이이는지이이는하이이는것이은는다이는는이이하것이다이것니니다.이한지하은가에은하는이에는다이이하이이니다.다서는이이는하다하고하고이는는이이는이이이이것니다이다이는다하는하고하라이이고이이니이이이가는것이는라이다다하이이하하이이는수이이는이이이다을이고는것이다는이이니을이다하것니다.\n",
            "에하다이이가하이은다.이하은이이이라고하는이라이는는다이이고서이하고하이서는이이이는이이는것보다는가것니는다다이것니다이\n",
            "에니고하는하은이그고그에이이이이이다다이이는이이은는는고이는것이하다것니다이하고가이은고하고이는이이이다이이이이것이다하것이는다하이이는하이가는고이이는이니다.그이이이이이은에하는는라이는는다이그에니이이다.니니다..은이은하이에다하하지이지이이이을하이다은다은가는은은하는하고하이고하이이이는이이는것이이는이는니다.이\"이그니다.다하는것이는는다\n",
            "\n",
            "Epoch 7/60\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 3.5876\n",
            "에포크:  6\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는이라고하고이는이다.그이이이이다는다하이이이이이것이고이이이이이이는는이이는이이이는것고이는것이이는다이이이이이이는것고이는가이는다가이\"이다하이이고이이것이는이이는것이하고이이이는하이하는이이는이이이이이고다는다이이이이는나이하고이이가이것이는는이이는다이이이것이이는것고이다하한이이하이가이는하이은는라이이는이이이다니다이이바이이이는하다이는지이이이이이이하이다이이이이이이이이다이가이가이이는이다하가이이이이이이는이이이는이이은이이이이이것이는다이이이다이이이이이이이이지이이이이이이는가이이는이이이는다이는가고이이이이고하다이이이이이는라이지는이이이습니다.\n",
            "\"이이이는은은이하고이이이다이이이이이이다이다이이이가이가은하는이는는하는하는이이이것이이이이이이는라이이는이이는것다이이이이이는다.가하이이이는가다하하이이이는다하고이이이이고이그하이이이이는것이는라이이는는하이가나이이이다이\n",
            "\n",
            "Epoch 8/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 3.4060\n",
            "에포크:  7\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는이라고하는이다는것니다하이이이것하이에에이이는하라이이이이파이다이이이이이이가는라하이는이는이가이다이이이이는다가이라이이는는다다하이이이이바니다하이이는가이이에하이이는다이이이이이이는것고하는이이한는이이이이이이는는에이는이이이이것니다.\n",
            "이는이이가가은하고는이다.가이는이이이다다하로이이이가이는하이이니다가가이는이이이는다하이이이이는이는다이이이이이다다가다이이이이이는고하는하이이이가는이이이이이가는가고서는이이이가이다는이이이는이가는것고이는이것다가이다리이다이라\"이는하이이다하가로이이이이는다.이그다이이이은니하라이는이이이다이하이이것다는는는이이이이이로하로이이는이는이다니다.이이이이이다는다하이가이이이다이는이이이이는이다이는이이이이것이다이이이이는이는가라이이는이가다다.이이이것이가는하하지는이가하가고이이이고서가이하는이이는것이이는것이이는.이이는이이가는것다서는것는은\n",
            "\n",
            "Epoch 9/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 3.2284\n",
            "에포크:  8\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이에이하고하고이그니다.는이고이이는하고이고이이이이는이이이은이이는이이이는이다이는것이는는다이다이이고이을로고하다하다다이그을하이이하이고하는는고이는이이이이그니다이다그는이다는\n",
            "고하는이은이것고니다이이서것이은하이이하는나고하는이이는것이이는이이그는하고이이고이는는에이이이는이이그고이니이는이다는는은이는에것이것이니다.다.그하이이는은하은하는이이는것이이는이이이는이이가이것이는이이다은다이는이이이는다하고하이이이는것고하이이이는는것이하이이이는것이고하이이는이이이이나이이는것이는다는이는은하고가는이이이이이는이이고이는이는는이이는것이다다그그그는하고가것고하는이는는이하고이이이이것고서는이이는다이는하이이고는이고하것이이는나이는다이이이는이이는것고하다이이이는이고이이이이이이것다것이는는이다은는이이이것고이는하이이는이\n",
            "이이이이는이다이이고이는이다이지이는다이다니다이그은는고하는하지\n",
            "\n",
            "Epoch 10/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 3.0580\n",
            "에포크:  9\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이는이라고하고이는기것서다하이이이바란그이고이이고가가이에는이이는다이그이것니다는생고하다하이었것니다라이고고이은고가하이는것이이다이이고이이이가이지모는것이다다.이그을하고가라고서서가는것이이는하이고고이이한이이이는것이이는이에이는이고이이것니다.다다것이이고가은하은하이이는다하는이이이이가이고이이이이다이가는것이이다이것서나이이이이고하는가이는이이는생이이어이이이생다이는이이이가다가는하것이가이가는하는이는가가이가는이이다다.그는이이이한것하하는것이가는나은하는이\n",
            "하가이이는이이이지고이는이것이가는것을이다.\n",
            "은나이이캄은나이하로이이이가이이는이이니다.가이이것이이는다하로는이이하는것고이이고이는는이고이이이이이것고다다이가이이하는이지고있가이이이이파넬은이이이이이이는는다이이는이이이것로지서이이면다이\n",
            "니다은고는는은이가는니하이이니다.\n",
            "은다이이이는하이하다이하이이이고이이에하이이는\n",
            "\n",
            "Epoch 11/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.8873\n",
            "에포크:  10\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇지에이라고하고이그리고니다하지이이는라이가에이다은는이다가가고는는하이다.하그이이로이이는하는이는는다.는것이이이것이고하하고가는이한이이이지이로고서는은이이\n",
            "는그하지고바이는이지이는다은고이바이는는이.서이이이이것고다나다이이이이는하이이는이이이는것이이이이이가는나고가이이가이가이에은하는이가이라고가는이다서가이다하이고이는하\n",
            "는것이이나이로고하하고가이이이그하이는이하는가는가는이이서는이어고이고다는이고다가이이나이고다나고하는이한는나이서있이이다나에고이이이고이것이는을이가는다이한가이그은라리고는는라는가하이그하고니다하수이이는는이이하이이이는것이다는이이는는이이하것이다이것이서는이는하다이가하것고이는이지서속는이이이것서나고도것이는대는로고이지니시..그습니다.\n",
            "은것은하는은하고하어이하이이로는이지이는이이는것니다다는것이그나고가하고하고가가에서하는이지이하로그을고이이는은이다.는은\n",
            "\n",
            "Epoch 12/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.7129\n",
            "에포크:  11\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇고에이라고하고이는니이.그하이이이이가하라는는이이는가이는다\n",
            "바서는은어이라고하로고으수이이다었지다다은은고가라하에은고하는이이고었습별다이이바생이은에하고이는이이는이이니이이이다는것서이는하이가로하이가고이고이가는지이가는이다이가\"다은가고서라서라고고서하은이고\n",
            "고은것이지이이는지다이고하것은는다그은서라이는것이고하.이고이이그이라이는는것이이다하이하것이고이는는는는이는하이이것로로고서이지이이\n",
            "습.하은알그은이하는하는는가니는이이이고고바로는에이가는다이이바니다.가리고이이이에지서하는것이이가그그은고이이은가라는는는이이가다이이로고이어가라는서는다.고가이이하고도니하하이이는는이이는는이이생것고다는것보다다하이하고하고가이하이이는이는이이는이이이것이것다이것서는이지가한고하는가고다나은리은이이어리라에는이고이는이지고\n",
            "바서다이것서는은하하지고하이로고수이이에있이는다.이고이이이이이다하\n",
            "\n",
            "Epoch 13/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.5589\n",
            "에포크:  12\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇고에이라고하고이는리이니다하이이고이고이이고이이이다는것이는것이이는것이고가이고가는이고가나이는나이그다.이가이것이는는하는은가이는가것고고서수이는바이는을이이고이이고이나고는는이이는이이것보이고서이지다이한가가나지.라습니다.\n",
            "\"고은하는은하는하고이이이이수이에는이이는이이것는것파다는것서나한하고하고하을로이이에이이이는다다다이이하이이로고하고는이이이는그하이이이이는이다수는이이이이가서은하이서이는가대한지이이이고을어는다에이캄갱하게을캄니다.\n",
            "고고파하라리하이하을이지고이라고이이다파생은하다하이는것이니는이는이는하고알는에이것서것이이것니고하은하고이이고이하이는이이이는것이는이것이는는가고알다이한하것해어는이니서.하고로이보이가니로는이바니지가가리것니서.\n",
            "\"은그은고가하는은하지는에이하고이다이에있고는이이이것이그을이이서는이가하는캄파는라고서가는을보그니다은이로고해니가에지습니다.\n",
            "\n",
            "\n",
            "Epoch 14/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 2.4041\n",
            "에포크:  13\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇고에이라고이로이는니다니다.이것나지는다는하은알한이가을을서이지이니\"가는은은서늘은늘하이지수이이.에을것다을것이가한다.은리하은하라의은하하고이는이는것보이는이이것다나고가이지다나갱한에은나는넬은이고다.하이보그바이나지하고이.가갱러른들은이은은라가고하는이이한로고하리이이다는책은하이지이는것고수는.이라래나그하것이바니.하는는라고하게가하이에서다하지이나고이다\n",
            "있이다은것들하한하게에나하이가이이지파넬에는이나는면그을는을별.라해그을캄파을은은고었그을을도에것다다은가는습니다.\n",
            "\"어이은다은하고하로이이라이수이이이다다흐다은것이은가는라고는하고가한이로수하것고이하는\n",
            "러하이이이이는고서고이이이이는것다다에이이는는나다의있이그이로고이는을보이는는다다이것바고이로수서고하라로이이을습고다.이\"생이한다만지서은것이는나에서는은하고가것고들을에서는이하고하가이을로고서는모이어이그파하이도다하가니\n",
            "\n",
            "Epoch 15/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 2.2556\n",
            "에포크:  14\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇이에이라고하고이는이가하른하지이이지서가고하는가은미늘은어리지아어는이어로이그를를이보서가그하는것그하게가서는는이이한지이하고로보어는가에서는이바.가보어는로고서한이하고이그그하이고라는이하는는는별나이이이이로별을그고는이이한.하서을라이다는가은하이고고었것니어는이는생이은고가이고서지이는다이이는는이고은이이이이로해서나지이이이이다하은\"캄이가는가는하에하지고가고어고이이을는을어의것이이이는니어을이이가이가다.이캄파가가는라고하하그서리로이별하이는이하고고하것고이이수는별이이는하이이,이이은는것이이는이이나는이고이이이어이가보서나이가이가이나는이에들가이나은것보서나그이이한이고가이에는모이는에나하이가니다나그이에는이가의에이가는가니서가이바을가은어리니가는한러하는이지이로고까에이에서한는다을라고을늘요.에그서을하지을것조..한습니다.고캄고은하다만니서하지서라이이이이에고에은다하이이이그을\n",
            "\n",
            "Epoch 16/60\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 2.1171\n",
            "에포크:  15\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게에이라고하고이그파나니다하이이면이하이는하이이가는이는이것이이나나는서다이가이가은이들서고이가는가는이가이다이가고어고서가이지서나는것이지도이늘은고들고대한지는하것이바이다.에은이이하지이것서하다이는이모은은이는고이바서는하게이것지하나이로지이하고가리이는다그는것이이고이한고는하고이이나이는에로이이이이것이그다..가는이이가가은하를로이서대나이는고그니다.\n",
            "\"고것니가하하이로고이이가하는는이다.면이이는이고서가하고이이고서나이수는이이는나이에이것이다미것고캄다하이대것하는하라고는는나요이고이이하이보이는을것이는는이이가바어고하것보서미를게러바이고대이보는는나이러나지다로이로고가그들는습도니다.라고그이모은하은하수하이는것수이에.이이이나고가이나는하가이것서하이라보고가이은이는이다었가지가는이바서가은가리로고서한고로고이고고나이는것것그별넬이이캄나넬한가는는서대라고는\"하고다다\n",
            "그리이로이\n",
            "\n",
            "Epoch 17/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.9745\n",
            "에포크:  16\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇지에이라고하고이는을고파넬하이이이그그을수에은이가미는는은지이게이이이고로다게는이나이는다다그이넬이가들것에서는는것서나가이대로고파별은고가이그다하리에다은나는가에하지이별하이보어그니다은라고이이가이는은하게하이이가는것서이이하이이나리고이모이이이은나는니이는서이늘나이이고을이니다.것캄는나은은는하하고가없이보이이이지이하는은이가는가자는라이다이가\"어의다다이한는나로이그보고어늘에고가니한는이수여것은나는하에서가이게대이보니다.\n",
            "그을다시가가은은하게리은는나한는게이이하로이고가로파넬라이지다을이습.에바\n",
            "선생님은다만.\n",
            "습니다.\n",
            "\"고이하고은하는하로이이한이이이에는이하는가은이가가까서는아서는래나은은보고어이보서는가이게이이이한가로어는이나더는.하었로그서것니다다가이는다하고가에서하이이고고이이는리고이는나이이는나고니이로이가들을에있는는다.나그이을을에로넬하고가는한새니그그서이이리를하이\n",
            "\n",
            "Epoch 18/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.8451\n",
            "에포크:  17\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇지에이라고하바이는새고하는하이이이바별이이이이이이미이것는이이이이이면게이가는이가이이지파넬가고서나는이을로그서리은있보서그고도하로하자이가고하고을이습지다나리있이님은다시은하들이이는로이하것이가이는한다하이는가나이별서라이이을어의들나다고\n",
            "가나을로보이보는희하한캄것고이로이서라까로고있이다하이고가을하이이지이는나이는고이이나는이고가것이면갱이보다나하고이는지다가이에는이이나다은하이이니다갱가서수이이이가고지넬의지이이이나이나그바있는가갱자보가가스것있어지않다가가한은보이그는이하의의하이이이으다는에바이이이이한은니어게모이가이가바이그그다하가이나의가는는는이가이한보로로로해서가이한고그그.하은가는생라는는하하지가고어,그고는는아\n",
            "의바지에하것고다스로로그을을별이지는니.그캄을고은\n",
            "은다하게\n",
            "에은지가어이는이나고다.로이이이서모들고이다니이늘나에캄이하라가하하로들에는는이하는지고그이을바수는\n",
            "\n",
            "Epoch 19/60\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.7234\n",
            "에포크:  18\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇고에이라고하고이는유이하나하이이이지이라라이는이이이것은이바이것서이이한가이이이한이모이가하는가이가하다서라는아어이라는고하고하수이이이었서지다있가이이이라의으은하있는이미.그캄은이는고는하는는지수이것까지이에해까그이한것보캄그을은대는늘에릴도리커니다다.것가하별보이에있하고가는지고이는을고이로의그은이바서것이다습니다.한바고하한지은하서하게바이이에있이이고이나바이는이이이다이이이이이서이이지이이이이이이모이가는이이이이이다하가의서이이이이지이어을있는이이이바래가각것에서이이가러을리고알는모이가고하것보것니다서가리이고하가가하서로지이라지이이고아도다래이\n",
            "이는지이이넬이는한는나그은이그서로까에서가하이가한다을보은수는이가의로는기이지고서한을바.없그선을니다에조\"지니눈다에\"고.조도니다하그을이고이그진에는이캄기이하이었지까서지없리지이은에을고고을은고은가시진것이지다다도어고하지하라의하로별\n",
            "\n",
            "Epoch 20/60\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 1.5942\n",
            "에포크:  19\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게에이라고하고이는파면시미하이이이바수는을것는이가늘갱가만어을캄서라었것하고수그에서.은는리이지양하.서로이고이러을지는지다.나가그을생을다을대은세의손.물속습니다.조은어이이다만해서하지가이대답서는라고가은는다.자으다은하는이해서알안은수이에다속었고넬여가양나을가다의그렇게의지희문의바니캄파넬상었지서수없을없그바은.을가그은습은한모가은생리라다만가에하는이가이로보어리을에서가이바로이렌의을은어는한바하는것하수이고서하고하,이가양나이고이하지\"대의보가나리는다은\n",
            "다보가은가니고이이로고가가이리해이는생.나가이라보그다넬은은가이나로가리었다아어리가파나은에는수이고하이고보이을분이이이는나지가을라서이미.서가은는을하고하별아수로파바을모이지서지고..그에해늘은모은은수의었어을것다하바가바은가이을교지이하고입어는늘을라은더이이는없을것을바니다\n",
            "그분은고대이모을하게하고.다.그해고이하이은로서는것\n",
            "\n",
            "Epoch 21/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.4817\n",
            "에포크:  20\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇고강이라고하고이는유이하나하이이이지실라더모두이가한을을를일다고다가한\"은을하는모은하의에이수것지다하고이바을가이으있는이나한러일이한은이서가가별이이가은이나어리한서이나는하자가리하은.에보고아미지니다다다그생이이별요하에있는하는이한고이이을있는다.한바이가바것에니서하게바나가이가을다고이나고가이가은은에면선들가가나가다게그기래이한은면그하어이그는가하는을한이이가아어는다어생속생나가이로고이이이나은가는다나이가이가가나리서에들가는가이은고보고어이의어가는다수이가이것바그에.에양가이한한가.그는을지이가은하는의캄서속은가고니다을,고고다어리가아에을\"면고하바보이갱을로고을것지이이가다습니다을캄캄생대은고씩하을보없이다다이라라모이가은가에서가\n",
            "가서나도나는은고은어한모캄을들다.수가없은하고생이서모이가래고이이리지에서가리는희이한으은은어고니어라가은은게이이가.그하는다이다가가은수는이고는가하한\n",
            "\n",
            "Epoch 22/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.3749\n",
            "에포크:  21\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게에이라고하고이는기나하나하이이이가별러리이가이가가나을서은이가는나의가는하모이가한게보보리이에서가의은바이이이을하로을보이모이가는기다하고이다서나도없그이이면을하가는나은하미가은은가리모보는하어지게어고있고니수이\n",
            "을나을이이이것이가을을캄기는라한대가럼을수없그.하다알고하생겨은하이는이넬이가그니고이가서것서나는하는이나은모한고보이모서한가이하하고가나하말하이이는하나리가는하이이가이이은하에이이들가는이라이가파나모이에서가하을리리가하나를수는하것이하이모두그바이는대한가미지하한이.다시은이,은이은나는의것이는모이이이고까보가가다하가들더은보가은리서어습니다.가리고이게지만다서하는것이이하에는하고하고이미이이진는이이이는이이이나지어이가것다가미라캄그양라한한하가는리고하고하하은가이그하있이이는이가이는는가이가지서나이그고어이나리은에가는하가이라고보이어리이어는다하고이가고이가이고하이이나는가\n",
            "\n",
            "Epoch 23/60\n",
            "14/14 [==============================] - 0s 13ms/step - loss: 1.2742\n",
            "에포크:  22\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하고이그파가하나하것이면가하리는모들는가생하의지에다에이어리는파갖을\n",
            "도별,렌니서\n",
            "을습니을을것에고있니다.책은고파을이에하서이\n",
            "다리에기을을라고가로지보진그생을은지럼.로일어하물은하고하게하이지이하고이이이하이자캄는이더이한지이을쌍고서니다란에대자을안지는.었다습시다생캄캄어은라고의것하로수없이게은나있가다습바고가하모들이한가하러나는의에이가하는별들로까갖을나리에다있이은분을자보이을이있갱란고일다가그은이가하에라답어의라이가요도바로가리면보나는었면바하한보들이들고에을가모자그이모이가을일요.다\n",
            "선두가은하에데고습기다하요니어그하모만그이어을없이는에서는스가이것은그어로로을라는한로고한그그하것었서은나라에는.이시는.이지바을어서는것어알갱\"러,것도고가이지않어이\n",
            "가을나이나는이이가그은은들라보기대가의박나이이도.그.리니에서한한희게하지가하를알명하바나아그고그하는언이푸들아하는.\n",
            "\n",
            "Epoch 24/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.1675\n",
            "에포크:  23\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하고이는이가하나은하는이가희가이모들이는서가의라는나에이나서로의바하지들은모가고로이모아있는다하는바나다하갱이로이모이에보이지다다하다해가그가가은있이는보\n",
            "가한가이이이지다가어의하이이이쪽은하의바이이이가미하는이이모가가나리는이서가다하이은이이서나서의는이이이가이모들것있다가나나는나를이가은하은들들모캄은나는의에가이이하서이보다보그는생더이모미까수가새어니못그두더보양고이었습니새.개캄습이라모황것이이또에두가러생습들과더대은게그은게빛만도다내이하하이면이는들각이이이이가들나바이이이가양나는이가이가가가리지캄서가는나의가의하습고가의모강면을하다시나을이하은을일는그것캄생더지고것고어한지습니다.\n",
            "\"가이은모은하는바로지이는파하이지이바하기이수는이모은이이이러것이어미하이가가가이가나이는이가가가는나에두가서나의이리고가별하한로가이것의나리요다.하이쪽대이이에을하지이이지\"가그그기다래더\n",
            "\n",
            "Epoch 25/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 1.0876\n",
            "에포크:  24\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하고나는이가하나하것이이캄어대답모들고알대지도그\n",
            "자생래은다.\n",
            "시으니바리는이고한그은은하이이어른는에하는게이나이렌에어을지별나라가미고그그은은모가가은당는아하게다를가한나다어갱이생서하의에보이지않하다고에바그이나는이고이바게모하나캄다면나한그하하이보고을보강에는이이미가은일가하에면더들별는이라고득진니개이요서다은그이어이또가아고하게갱가리을대요갱있이지않은니다.가바이자은이이하하하가이나다이더더지이어이라강키니개개은가이지이물.이또또.이쪽은.이리캄망대희미하게하라수없펴조로는이하지었해아일습니다.그은자은하지의하는하손의다런그캄니이니다바그하은지도이가하게모하다.\n",
            "희나이이하하는가은하라희미라는아어는이지이하는하어이고별자은을모이가그른지다다나에두나의하그의로이들을에강니는것바나가이파을는이어대모희리,에기어한지양하을이고까그그에을는이리나은를운.그기어라이지고하라게이그그\n",
            "\n",
            "\n",
            "Epoch 26/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 1.0053\n",
            "에포크:  25\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하고나는기가하더하지이이보까상습니다도그러생하를고들서지않아을는에서물이다은이득기어고에었것는나가이그그이다에흔고가는라아말한고별이가로다가양하은나요가한그진리습이이희조의게하로의언가미,그있니다.로그리는습한에.하고하러하고두는하은이이지이이지을이는이대한기미한에생다서다시에파별은하은하고의그을에요이지고의나있손.도그선생더들리은.는않양치니다은보은다그로습니고하다도고이하게새을이는습면이\n",
            "이하이이나모만이가는지이갱한들서는그요다의가다에이고가하조을로고이는면나고이그습니이.그을두이늘는형기라는하고스스로니다그었는이이리라그니이한는다나한고이하니나에해는가바하갱이에들그습어는이지다나그하에두니다.은있가보이게에서하는의이고가이어로는에해면나지이한바니.까에을가은가하가에라을을일요라요어의그진은하고데\n",
            "조보로하지속면지있로고있이아은게을것고하것이나득파하고들면는대자혀리는이는록을\n",
            "\n",
            "Epoch 27/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.9405\n",
            "에포크:  26\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나그파가하나하적이라가하는이모두가희나하의모어한자는이라고하어하렌것다서나하이가이이고리서모두이나이는나고니다자하라가을모들가\"니다다\n",
            "선생생은고이라고습니다.는모두양하게새하서로어에을습그생이지고로그렇고생하다\n",
            "조바니캄파하라지고로조었을지는아\n",
            "캄고하선는것기어를책리는다치고가그고서부에\n",
            "고니지는.은.\n",
            "니어가을을다하이하게을그럼을기는이의이은니말수이그다것면다모을하이알하게의을서해적이가니그생갖은모은희가가다은늘명가거아라의고하스것것이수갱러이지이은한하가고다서쪽은이는속어의지었수하이지다게을바은는이이라로이어고모이어는지바하가여다를가니어을모이한게고하겠을캄다서그러면이늘은을리서도손게이하것하고가가면별나이는고이나가는을고보가어나나가럼다기고가이리강가는이진트가이지들하요다한다그이자보이어을하에는듯한다이가공습습니다.에고그그은새은을서다그는는손이이고은고게한니다어는나\n",
            "\n",
            "Epoch 28/60\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.8582\n",
            "에포크:  27\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나그유가하른은적이라가아라고하는가희나하가양하지강어이라들어리습캄은하빛나그이각의리서은이이가박을하보이에게대가는을일고가그그다.그공자서나는라한그니다.책모가그하은하은하수없하는하모의라의조바고까이는하해\"로그러에대캄고하도도도강을.없서가지희면언물은하은수고을얼을그이고함도이니다.는는이지한하가하하로해어곡을은어는고고하,었사수이많까지는다라자,는것은를에서어일다\"그리의하를수이답보이에에있에하이한게가나을에고있이가은나\"캄파을라고늘리른보수지니조명까것와에이양고이그언보릴어리을모서.\n",
            "그않나렌니을있요하게한고들어을것고그이하은우록렌에들는는한다운로하고보이까책에이서하이희이라보그을나고희늘라나가.라있가아하것은세은를리있는갱함저게얇하는보에니다.이은의고어가.는서운한러이가로는로고요.\n",
            "을나습니다.나러생그은가은은하에강을는손미리게일어진물은별를별이하고니지이는서그서대\n",
            "\n",
            "Epoch 29/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.7844\n",
            "에포크:  28\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나는유가하더하적이라고사라습니다보욱선생님은가외서습습니치\n",
            "\n",
            "자리캄칠판새에니고조바니없검은이에고이지었습은서.그바생그은의판이서수하바다방나캄은갱수이라무이거보수고않서나가이이한가이는하모두이흐나속이지도이생을는있캄니한\n",
            "않나물해서보는고하하고보로은수날서이서이지..이이입요다요늘은\n",
            "알이가는가이스보이습넬미\"어는더또이게판하수수새니다대그하은보이이,\"다다하에이이늘라에이고보도가미하것가흐나수가면리수이하고있가양리을보양라을나있의에에고이모하을리있갖.을희마해하고들고을습니다.그자생래은는리씩서게한바로론니고보라도하로그은할다수없로언지다버선네습지바.\n",
            "에습양니다시\n",
            "바그어파두는었의것득게버정니,다에캄가양지함.\"습었을도의있니다니다으는그을있이지하니그은게하것이과요는이\n",
            "파나고하나고습다.그에두면이들에생서게하스에이더이을,서나이또만니다는을\"모두속서이습진바기니고.다\n",
            "\n",
            "Epoch 30/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.7221\n",
            "에포크:  29\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나는유가하른하적이라고넬라고하는가희라었그다하있이어의라라는라이하고가보하\n",
            "로어하는태나는가강바로이까있고들어이흐바하을대에수이이고는지다다.그이이나이모은하수는모갱가희한해고에에라고않럼스속은다.그하고이이은다고서서는이이미이고하다고으서이면는른이고다나은수모을서는나은모두가양을을으모가나고리의습은은은를리강지할모판게게의고이물은생생은별을갖는.이니다.가은분을어가모고은수의하서를그의자바는겨보지에는버갖다으니니키을에사책을다에책그졌기속도없기서니이라지그다을은라고기나일의한습니다.이러가보하모은은하수가서고이모까모고별이한으가한며에두더래늘은은럼박습을,못을것가이하모만습그다고가리의는하는판한만어의에해다시그은하는것보.그의것는니다고가가게하보가.에서나그이하이가요.을'가는한이나가데바고,한모은나강의리모서라속자로가스우에서고한니\"하리하로을서가에에이는니다.을으고그즈\n",
            "\n",
            "Epoch 31/60\n",
            "14/14 [==============================] - 0s 9ms/step - loss: 0.6668\n",
            "에포크:  30\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에는질문을던졌습니다.\n",
            "캄파넬라가은을하었습없는러\n",
            "선생하은의새니고습기다.는러그그니게만그하로고하한가이하는의다하는하데이나습까즉는것고그이이가에를에그의가손나을의습니다.그선모캄을우외하는다안시하고이이캄으어,여것이희미가리은을라게가좋즉넬의있의분일어고수있을자이라서보그우서있래시나었고가운로가리는은리의가요바하지보어게보보는,이아기가이바닥만서이란일그이이러기지가늘라는써나\n",
            "진그그로바진.\n",
            "보니지아하.었다하어가생듯갱가의는고가그가은다다의해서지는하요란그을바은자캄고가라는손두지조쌍고나의\"다.스로습니이강로이서이니다만는가하하다.가하에하어고이다하로의이별이그이한이다것이가서가이가에나그하늘의가\n",
            "\n",
            "Epoch 32/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.6075\n",
            "에포크:  31\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나는유가하른하적이라고만하고하는가희더하수는이이아어럼책못것양해기를답고도그다하로\n",
            "그은자지않라는으니아라니다은이일정은니갱었고하이가이지고니다는는이나는늘은가로진해서가강서보이고도로은어은하수이대지않도가바런분양다다었지하는가나었습그다.것질어가리는들은하수한캄이로니모래두는이에고다.이하론을서다.것그알을것할은다하한리니님을겁태지는하바만책었것요습로서무지이이의하습은다도들선생님은모판무는희기다물\n",
            "래생은별어,그고었니을물게서고습하다알해고이넬서모리고는해은이한서서를하고서지희나로고고는이면모좋한강별것또서과을고수은하은릴대에에을자이도다.은되그을고시가희서하녁불손그생것의지수하에하다하,대자것이도에고는다모.쪽시\n",
            "을을리지고하게조바게생해에좋지이하고이넬로습을어캄더모두\n",
            "바다히,지니개고찰로러대\"\"었이또다.그다다보이에을대서알라있고이다그다다가별가있희는의손을속는서는\n",
            "\n",
            "Epoch 33/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.5629\n",
            "에포크:  32\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가은을하었습니다\"\n",
            "선생은은의형하에반짝다물게러면님이가잔뜩보이지을을\n",
            "란양면볼이곡은은만는켰습니다.사\"의하어한새지은나었이니이로그그은이들의가습다다하물이더래하는생을하고이,개당역어물니다미을\"또에지이었별하는새말를을은쪽는는아,그하습니이로고어득습은다만니다로이렌는씩하하는고하하자빛서는이에서이지이다이으서나에다쪽캄지넬라은모강그서을고은바하가하안한모두하게러이는이여은로는이넬을가서늘거다고서그러처럼.로한하지.손을는이서하은가은시히기서이는아어는나것스그요지어이각우가들라운데이그대이로는을로그즘.\n",
            "되.그그것.이도바을니서는한가한더시바은지으아명럼어개것러쪽은라갱\n",
            "\n",
            "Epoch 34/60\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.5188\n",
            "에포크:  33\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가은을들었습니며명하선두나은자에해습니다다에강니오진우은에당이물는습니다로조렇수보이게새해있로고유이가이나이는에고이하나이나가바.별이갱모두가가의에라서가다고하겠의내속은가을있는넬라각일다어럼것에서바은가라가고수시.고모래의하이우양은하에에당지희스하습니어.\n",
            "고좋,니다시이이었습니어.그있것이쪽의히나지는하고가미하실은강로고하지리이아보가하하는이은이분양가고이모서라이가서보리가라하고일나한수이보이하별더라두것이\n",
            "없대도니다하에가한기은다않을가아어한하그고는것은가득이에는하이게으래가이미에이가선생은면는와는속처다하물게을서지알흐과하도이분했모은다.에모희가하경자의서\n",
            "그해라\n",
            "\n",
            "Epoch 35/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.4787\n",
            "에포크:  34\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐더흔적이라고말라고있,더희미하고그시것있습못로는가그생각대모새다그어의하은니다생즉게대바하지록니하,도다되이어은하는이에않이면가각는커서가가이속을리있게은'이는가다고있이어이로가어는의에이가이다로,그까해을나요지.그에물대은은은책은요..\n",
            "다모고도득가데은은어에하지않래의하게나그니어리이론있이은가.그고이더은있라나의는떠이니다록이리캄해서가가지서하답것습은어이리은고하게의두게이것에무지그나지만하한로별들을라강할는의바니있이고가흐태어수이없고들지고있습많양것은캄파을하는두은지릴수리에것아정다다은하바니에시\n",
            "해해하이이이고조것해우은이이른미이그로한로나고가각는지..은로강나리도모은하\n",
            "면그원보도않자의가고을하보가않조겨어의은적이가고것웃,바하가희나가나들대자고가의라리리큰록다시지그바하보여살.그은에라한다.\n",
            "그게손이별하은하서도의시를는있는고지가않그것에수에다은은는이버\n",
            "\n",
            "Epoch 36/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.4441\n",
            "에포크:  35\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가은을들었습니다명\n",
            "선생나은의외하는것잠시물보러미캄이이답를보서그만,서가\n",
            "가서가도는는\"가은어은수지을해고가는가둘란양을속은가요어.\"켰있기다하는스이하수한이그이지정리나가이속.\n",
            "그이고보가는은다서득손나고이의어다.가래를강희나로로하하의해는하라고있이는것보은서다하것이이고가가이고하는가흐른나가이늘지아어고있에세요?자듯갱그더이지니습어다라다였못데그생에니그\"가은다이하나는다은가한고알갱이보고하어는은가니다미이이이니다나의에이이이나가은에두바별더대른세는사까졌습니다.그일어라고가은고하수하답그은나는서은이이고가손게들서모이흐나나리고어이에서자있강들서가그그띠으쌍는원이수\n",
            "\n",
            "Epoch 37/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.4134\n",
            "에포크:  36\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서모은하명이손을더들에자이는.조바니다록빨야것고로번이습습니다넬것도그었모에있고하바가희리가하에있두이고이답로는어하고을나이한게로어그다에것들\n",
            "러하그이하하게보이그이이는라지이모이이한나다다\n",
            "은나해늘나에들고하게가강하보두그래지이면리하이가,물당은늘을교희을한고이어런것기하,하은서가하나이그는것모은수이모들알손그하자가양나있의태를한역대은에들있있고하었생다나어이에있가이는은이가진을을이는가다일가의어습것을어는들로그하우의시,니다이하한알로하은에고말라는은다.는고조고하었서고이로까그습니다.\n",
            "리생은를는만하고하고하물의에서는이지이가고하각로으다라캄\n",
            "\n",
            "Epoch 38/60\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.3945\n",
            "에포크:  37\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서의씩하명이손을리캄으보라는습급쭈을로야은그었습니다국습니면도\n",
            "에생은하에만는지않고을게니아여아어그이님이나이갱거이이하갱것라들지멀하이이가다가그리있는이양나한어의에하고어을모강게진해과이가렌고하는니어은에을의하이지에것각나그것이이다은그리이들젠가이지어하에의당만,이쪽것이읽별눈는지\"이은알입니다.모것이라두렌빛하하이보가미로을빛는이이'가가별별,는실구나보리을요서에에있있보이보문조도을을있이닥미도도웃왠해는이에기별면는대는습서가을그고을그시모두\n",
            "리생대은적말물고습고이다다나고그이모두가나별은들도손나자하의캄다가교급를합안무보고어습니다는가각별키\n",
            "\n",
            "Epoch 39/60\n",
            "14/14 [==============================] - 0s 12ms/step - loss: 0.3684\n",
            "에포크:  38\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나선네은섯명이손을모두인지니다습시를새생러은은니우생러에이그서지.스로그리니더손모은하켰하고만니조바지는라한이지수책고러로다가속라로이없지서고하요다\"하것은은서가가을를이지저다시어이의고하쪽\n",
            "교의각많과이지별하를을있지은에나있서질은것에캄파즈들있의캄스릴에습니닥의에보습리나게새에기바진가새보들면이없즉었어가이이이캄는은에는로이이대,고다는니다.이쪽되있파하에?무희을을불리는도가어이지해,의이어면그니다.\n",
            "것이가고들하하벌하\n",
            "대선리는이지니,니다다다보서지그이모에여해서이다에상가있은게은가가이넬을가지파다일가는가러을의의는하라요수그진것캄보서지었강입\n",
            "\n",
            "Epoch 40/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.3304\n",
            "에포크:  39\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가은을들었습니며명하선두나은자두해습니다아에엇니니니고황고이갱을이없에해습습도가양했것은렇게판들희의하답로다유생은하,보이'고이하는는이모이자,이는에해서다아더책'그고을었고만책,없니.은은에지도었습은다게다고생각니의히\n",
            "의생이은로가이지한기이는한다나는라로하공별까은우보지바니다은은를나로시\",고니게의그가니것이\"가고은희버가이대속이의엇인지말이다.태을해\"나러하을이\n",
            "고를로이강이모고가는고서나가하다자나의까라고들는고하쪽흔태를하는이까지별하이고는까서을를있고이나은에대그을는이더른강다다되것해해고개에하고이불것보보록또여다이라고보그생하대고알읽하니이하는다다이각지이기의까\n",
            "\n",
            "Epoch 41/60\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.3114\n",
            "에포크:  40\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서자은섯명이손을더들었습니다.조바니도선생들려고하지,습양은는대로이까을에두모.다되하과를일밖스하로이교라에보없다리다하을로가을가은에있는다.\n",
            "의일요고여에다가한을보라을가게을어의에두가일처의하수그들은은가는과각는는는세도게럼,고,에해서사니다서것\"습을은시,을이고시는새다.것에기나그것진것하로들진그가답하게리도그이어버은가이지의않손라지아.요다생그하를은대이고조하로는무는다다이이습하니어들서있그나모두모생각이는이라강생을하은이지서지그하로생모런쪽떠다습한다.그바나하양모두은하알갱많두이모자멀이가고다아흐쪽있니고을의고하고이,에해지해있지다.\n",
            "\"\n",
            "\n",
            "Epoch 42/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2902\n",
            "에포크:  41\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나선네은섯명이손있자두인지니다습면를있?러은그니다에을고있그리다하니하에생는이손고이는고어나가니급히이다까나할세습니다한른에보캄세안새은고하에을일도운여이이니하는나로알이게이는.라모두나더이나나서그가자을니못른가강고버럼다리습다공은닫거고하하의만하요이리자이는이하는는다지니?지어한것기서자고조어이렌\n",
            "가라으딜이그리는고은의은에여의에로서다나뿌나조습기다나에알고가었다형그그캄리넬나라에니님버책리에\"가일넬아아수득하은별의고다갱란겨있는니을면지가양에리이.책속을캄의속에서지도는다,리이다은으로희어하에이을알한은하,이모즈지은아에는아했는다다기알이기어스\n",
            "\n",
            "Epoch 43/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2715\n",
            "에포크:  42\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나선자은섯수운손에자기치습니다입가다습조캄니생고가즈은게이한없그은나요.게어의것은하이이데는,즉이대고이나의에서것있다다나한캄파하수가러대들강에없고가이그서가이스습은나는늘손어는나에은고가.로를것모두즈히나의다.는들지다나은두해이로별이은가가녁과즈.그서곡어이리에고다은버고사이답을을많하고함나갔\n",
            "자고것은하나은가고어다이대이모들어의나바알다되나자이각보의바님이네두쪽가지만들많었한지얀,그은는은시는에좋아세버시어의것해기서득얇말것렌보가진히가그의을대아이었어하는손니다되갱은는이입니다것이흐다면그가는은이하고있별을손리공이을을리있요은를지\"그해고하이,\n",
            "\n",
            "Epoch 44/60\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2623\n",
            "에포크:  43\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네은섯명이손을더들었습니다.조바니도서당들해고로지,책을서말이니다.있도없하고이모에서라고않은이희조속조다하는것고이,도어났하구역들는한고까니분모있는이어은은대없고있있다미즉다한다은더리제만더고하습니니.의습니다니지으생그은모새\"그을은은요\n",
            "런하즉이하은이도가어나것있한는가한면가은가가의에어는에은한운처의해,지어는다보갱과보이자의렌해이가다에이라분하로은처고이니나\n",
            "고모하고언이늘에강있리고이지그스로는하고보이쪽은은리별는하고날미하게록보서는이지만는니다하.으어데보이에고이다물은,이이을을희라는이이있대는습을정었어다.요시우히은고는지하게은자로하\n",
            "\n",
            "Epoch 45/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.2533\n",
            "에포크:  44\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나선자은섯명이손있우기하다니다파시를고이파지는다서그것는이미에로기하수한가까들는그이을가양은은에이어손속처의습니다.\n",
            "렇모는렇다알고이로그유로어유하젠서라고말라고이라아,고하고그은두지가갱모이지가손다자은가않해쪽의조를니다미고로그을겠고리습만더바니캄기다선의새어,,이없러분만로,이과했것은서서는고모무많답저의고으서나보별은그교면쪽은모두니거운데하을하이자스을로들여모고이늘카은것그교다생희하까점쪽알버로그하라당놀빨럼다책다.그렇고가다하도어바이는유나의하지않이면가실라강보가있이모을리있가운나리고러해고하는보이들서고별별이에다가더들서은있요미조를니도이\n",
            "\n",
            "Epoch 46/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.2436\n",
            "에포크:  45\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서모은섯명이손을우들서습니다.조바자보하모황?서\n",
            "웃러서만라해습바니을더을모는진,했득해조못것해서다렇답양습습다대었고그리우칠판두다시는나세하란검은한의은서강방라에서의속보면는하입가을으각니까을이정얆리은은가에를는캄실라하도어의을서까서을하게않그갖을에잘서것이그고분을해에했는하다.\n",
            "\"보이넬들서고은바로이입가에이서도고바로가물는즈지가만다으로고이다생좋리는리은그희속하로어이모보게하세니도로많자자이하지었습니다.다바두가은모두는하수하함하는나자을서지이지고까모두카두으좋쪽은더잘니얀점버놀서럼뼛개었는아라고가고수대또는수득하나의가양다서수살이모두그의\n",
            "\n",
            "Epoch 47/60\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.2297\n",
            "에포크:  46\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네들섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 48/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.2137\n",
            "에포크:  47\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서자은섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더네황해서얼굴이새빨개습습니다.선생님이또히했습니다.\n",
            "\"큰망단경으로은하를잘살펴이면은하는대체무엇일과요?\"\n",
            "\n",
            "\n",
            "Epoch 49/60\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.2050\n",
            "에포크:  48\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네은섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생은은벌써그것을눈치챘게니다.\n",
            "\"조바니,하는알고있겠지,\"\"다바니는기다을'보이수이니득그진해빨이가이늘니있었지은래가요?보이고는그이실고강어닥나리모생을보희스렌이들서자로기까,은이더록도바니트잘에도니다하들모고그었별않하수가리며가은는서것강리답할수요니서고강하로자태이에에로희하지니시고그그고하로어\n",
            "생것하는\n",
            "\n",
            "Epoch 50/60\n",
            "14/14 [==============================] - 0s 20ms/step - loss: 0.1877\n",
            "에포크:  49\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네은섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 51/60\n",
            "14/14 [==============================] - 0s 10ms/step - loss: 0.1768\n",
            "에포크:  50\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 52/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1676\n",
            "에포크:  51\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서의다하명이손을더들으기하다.조바니,손에그지\"하다가\"\"히니손있이아하로이가물해를고는한다하라의\n",
            "\"서에서에하지\n",
            "해로이고을수니는좋그은하나님,는입고수손이이두고그정물가서히가읽하다손고이의고나요지은다히희별이가이데에한이이지은나는을즘.속구나을이해서이도다다있캄새나은수한희하하에그이거가양하라는라.손를,리있다었다니다히이우의이은의는이가은.로하라러보서처는이다.이그을이고언서을하수.손기하지그모은가이면히오아은하자미는늘기일니득일견나는로까들에고간하게들공은보록니다.그자기요어다.씩서도.니그을니하는라가시\n",
            "도득리은다고하의것그그래로러하지\n",
            "\n",
            "Epoch 53/60\n",
            "14/14 [==============================] - 0s 18ms/step - loss: 0.1632\n",
            "에포크:  52\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 54/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1568\n",
            "에포크:  53\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 55/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1467\n",
            "에포크:  54\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 56/60\n",
            "14/14 [==============================] - 0s 17ms/step - loss: 0.1388\n",
            "에포크:  55\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 57/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1337\n",
            "에포크:  56\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 58/60\n",
            "14/14 [==============================] - 0s 11ms/step - loss: 0.1248\n",
            "에포크:  57\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 59/60\n",
            "14/14 [==============================] - 0s 14ms/step - loss: 0.1214\n",
            "에포크:  58\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n",
            "Epoch 60/60\n",
            "14/14 [==============================] - 0s 19ms/step - loss: 0.1163\n",
            "에포크:  59\n",
            "시드:  \"그럼,여러분은이렇\n",
            "\"그럼,여러분은이렇게강이라고하거나우유가흐른흔적이라고말하고있는이희미하고하얀것이실제로는무엇인지알고있습니까?\"선생님은칠판에걸어놓은커다란검은별자리지도의위에서아래쪽으로희뿌연띠모양을한은하를가리키며모두에게질문을던졌습니다.\n",
            "캄파넬라가손을들었습니다.그리고나서네다섯명이손을더들었습니다.조바니도손을들려고하다가황급히그대로멈추었습니다.분명그것이모두별이라고언젠가잡지에서읽었지만,요즘은조바니는교실에서도졸고,책을읽을틈도읽을책도없기때문에왠지아는게아무것도없는듯한기분이들었습니다.\n",
            "그런데선생님은벌써그것을눈치챘습니다.\n",
            "\"조바니,너는알고있겠지?\"\n",
            "조바니는기세좋게일어났지만막상일어나보니분명하게대답할수가없었습니다.자네리가앞자리에서뒤돌아보고조바니를보고키득키득웃었습니다.조바니는더당황해서얼굴이새빨개졌습니다.선생님이또말했습니다.\n",
            "\"큰망원경으로은하를잘살펴보면은하는대체무엇일까요?\"\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM\n",
        "model = model_lstm\n",
        "history_lstm = model_lstm = model_lstm.fit(x, t,\n",
        "                                 batch_size=batch_size,\n",
        "                                 epochs=epochs,\n",
        "                                 callbacks=[epock_end_callback])"
      ],
      "metadata": {
        "id": "7RHlVos3SO9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "model = model_gru\n",
        "history_gru = model_gru.fit(x, t,\n",
        "                   batch_size=batch_size,\n",
        "                   epochs=epochs,\n",
        "                   callbacks=[epock_end_callback])"
      ],
      "metadata": {
        "id": "uXTuBLRZkReV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_rnn = history_rnn.history['loss']\n",
        "loss_lstm = history_lstm.history['loss']\n",
        "loss_gru = history_gru.history['loss']\n",
        "\n",
        "plt.plot(np.arange(len(loss_rnn)), loss_rnn, label=\"RNN\")\n",
        "plt.plot(np.arange(len(loss_lstm)), loss_lstm, label=\"LSTM\")\n",
        "plt.plot(no.arange(len(loss_gru)), loss_gru, label=\"GRU\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fmD6OOOwkTya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, t_train), (x_test, t_test) = mnist.load_data()      #MNIST 읽어 들이기\n",
        "print(x_train.shape, x_test.shape)      #28*28의 손으로 쓴 문자 이미지가 6만장\n",
        "\n",
        "#각 픽셀의 값을 0-1 범위에 넣는다\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "#손으로 쓴 문자 이미지를 1개 표시\n",
        "plt.imshow(x_train[0].reshape(28, 28), cmap=\"gray\")\n",
        "plt.title(t_train[0])\n",
        "plt.show()\n",
        "\n",
        "#1차원으로 변환한다\n",
        "x_train = x_train.reshape(x_train.shape[0], -1)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)\n",
        "print(\"훈련용 데이터의 형태:\", x_train.shape, \"테스트용 데이터의 형태:\", x_test.shape) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "QYORLYOBkWec",
        "outputId": "10f5de36-2c25-403e-cd5f-ce231988c8bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "(60000, 28, 28) (10000, 28, 28)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련용 데이터의 형태: (60000, 784) 테스트용 데이터의 형태: (10000, 784)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 20\n",
        "batch_size = 128\n",
        "n_in_out = 784               #입출력층의 뉴런 수\n",
        "n_mid = 64                   #중간층의 뉴런 수"
      ],
      "metadata": {
        "id": "0cSMnF8ckdDi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Model\n",
        "from tensorflow.python.keras.layers import Input, Dense\n",
        "\n",
        "#각 층\n",
        "x = Input(shape=(n_in_out,))     #입력\n",
        "encoder = Dense(n_mid, activation=\"relu\")       #Encoder\n",
        "decoder = Dense(n_in_out, activation=\"sigmoid\") #D ecoder\n",
        "\n",
        "#망\n",
        "h = encoder(x)\n",
        "y = decoder(h)\n",
        "\n",
        "#오토인코더의 모델\n",
        "model_autoencoder = Model(x, y)\n",
        "model_autoencoder.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
        "model_autoencoder.summary()\n",
        "print()\n",
        "\n",
        "#Encoder만의 모델\n",
        "model_encoder = Model(x, h)\n",
        "model_encoder.summary()\n",
        "print()\n",
        "\n",
        "#Decoder만의 모델\n",
        "input_decoder = Input(shape=(n_mid,))\n",
        "model_decoder = Model(input_decoder, decoder(input_decoder))\n",
        "model_decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eozOepCNwKp7",
        "outputId": "e31e4f03-f7d8-4f03-81e8-d945f49d9378"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 784)               50960     \n",
            "=================================================================\n",
            "Total params: 101,200\n",
            "Trainable params: 101,200\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                50240     \n",
            "=================================================================\n",
            "Total params: 50,240\n",
            "Trainable params: 50,240\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 64)]              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 784)               50960     \n",
            "=================================================================\n",
            "Total params: 50,960\n",
            "Trainable params: 50,960\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_autoencoder.fit(x_train, x_train,\n",
        "                      shuffle=True,\n",
        "                      epochs=epochs,\n",
        "                      batch_size=batch_size,\n",
        "                      validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Axsg7VaqwLpa",
        "outputId": "ff0fc2be-1aec-444c-b178-f60f8a713f6d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 6s 8ms/step - loss: 0.1985 - val_loss: 0.1325\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.1163 - val_loss: 0.1014\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0951 - val_loss: 0.0880\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0854 - val_loss: 0.0813\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0804 - val_loss: 0.0780\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0778 - val_loss: 0.0761\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0764 - val_loss: 0.0751\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0755 - val_loss: 0.0744\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0749 - val_loss: 0.0740\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0745 - val_loss: 0.0737\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0742 - val_loss: 0.0734\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0740 - val_loss: 0.0733\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0739 - val_loss: 0.0731\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0737 - val_loss: 0.0731\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0736 - val_loss: 0.0730\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0735 - val_loss: 0.0729\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0735 - val_loss: 0.0728\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0734 - val_loss: 0.0727\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 1s 3ms/step - loss: 0.0733 - val_loss: 0.0727\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0733 - val_loss: 0.0727\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcd548ddc10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = model_encoder.predict(x_test)\n",
        "decoded = model_decoder.predict(encoded)\n",
        "\n",
        "n = 8     #표시할 이미지 수\n",
        "plt.figure(figsize=(16, 4))\n",
        "for i in range(n):\n",
        "    #입력 이미지\n",
        "    ax = plt.subplot(3, n, i+1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28), cmap=\"Greys_r\")\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    #중간층의 출력\n",
        "    ax = "
      ],
      "metadata": {
        "id": "u2-bl9Z4wPE0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}